{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File \"AQM_Analyse\":\n",
    "1. Import the clean Data from SQL DB into Notebook\n",
    "2. Prepare Data for Analysis\n",
    "3. Create Dataframe to save the Results\n",
    "4. Create Loop, which executes multivariate OLS regressions using all combinations of 1 and 10 explanatory macroeconomic variables \n",
    "5. Save the Results from the Loop into the \"Result\"-Dataframe\n",
    "    For each Regression calculate:\n",
    "        Autocorrelation\n",
    "        heteroskedasticity\n",
    "        multicollinearity\n",
    "6. Export Results to SQL Lite into Table \"Results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import xlsxwriter\n",
    "\n",
    "import math\n",
    "from math import exp, sqrt, log\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "import statsmodels as sm\n",
    "from statsmodels.regression.linear_model import OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diverse Code-Snippets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jarq Bera Test:\n",
    "stats.jarque_bera(ReturnS)\n",
    "\n",
    "#LjungBox autocorrelation:\n",
    "PF_Ljung = sm.stats.acorr_ljungbox(PF_Returns, lags=10)\n",
    "\n",
    "#Autocorrelation als Grafik:\n",
    "data = np.array(PF_Returns)\n",
    "plt.acorr(data, maxlags=20)\n",
    "plt.title('Autokorrelation der Portfolio-Renditen')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Autokorrelation')\n",
    "plt.savefig('Autocorrelation.png', dpi=800)\n",
    "plt.show()\n",
    "\n",
    "#Normalverteilung als QQ-Plot darstellen:\n",
    "stats.probplot(PF_Returns, dist=\"norm\", plot=pylab)\n",
    "#pylab.title('Q-Q Plot der täglichen Portfolio-Renditen')\n",
    "pylab.title('')\n",
    "pylab.xlabel('Normale Quantile')\n",
    "pylab.ylabel('Sample Quantile')\n",
    "pylab.savefig('QQ-Plot.png', dpi=800)\n",
    "pylab.show()\n",
    "\n",
    "#ad Fuller\n",
    "ts.adfuller(df['GDP'])\n",
    "\n",
    "#OLS\n",
    "import statsmodels.api as sm\n",
    "y = df['UNEMR']\n",
    "x = df[['GDP_GR']]\n",
    "x = sm.add_constant(x)\n",
    "model = sm.OLS(y,x, missing = 'drop') \n",
    "results = model.fit()\n",
    "print(results.summary())\n",
    "\n",
    "#Breusch Pagan Test:\n",
    "statsmodels.stats.diagnostic.het_breuschpagan(results.resid, exog_het = x)\n",
    "\n",
    "#Scatter Plot\n",
    "df.plot(x = 'x1', y = 'y', kind = 'scatter')                                           \n",
    "plt.show()\n",
    "\n",
    "\n",
    "np.dot(var1,var2) vector multiplication\n",
    "\n",
    "var1.T transposes the vector\n",
    "\n",
    "np.linalg.inv (var1) inverts the matrix\n",
    "\n",
    "np.diag (var1) extract a diagonal\n",
    "\n",
    "Def fct (var1,var2) defines the function ,\n",
    "\n",
    "OLS_results = library for displaying further\n",
    "\n",
    "Return OLS_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beispiel Loops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------------------------------------------\n",
    "#-----------------------------------------------------------------------\n",
    "#Parameter definieren:\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "Anzahl_Simulationen = 1000 #1000, 2000, 3000 Simulationen eingeben\n",
    "Sample_length = 750 #Sample-Grösse für Bootstrap: 250, 500, 750, 1000\n",
    "alpha = 0.05 #Konfidenzintervall definieren 0.05 und 0.25\n",
    "Position_VaR = int(Anzahl_Simulationen * alpha) \n",
    "#Da unterschiedliche Anzahl Simulationen, dynamisch 5%-Position \n",
    "Anzahl_Wiederholungen = 5   \n",
    "#Konsistenz der Berechnung überprüfen, indem alles 5-Mal durchgeführt wird.\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "#Sample-Länge definieren:\n",
    "#Automatische Adjustierung der Sample-Länge:\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "Returns2 = Returns.reset_index()\n",
    "Sample_for_Bootstrap = Returns2[['Novartis', 'LafargeHolcim',\n",
    "                                 'Logitech', 'Nestle', 'Swiss_Re']]\n",
    "\n",
    "sample_length_adjustierung = (round((len(Sample_for_Bootstrap)-Sample_length)/(10)))*10 + Sample_length\n",
    "Returns_for_sample = Returns[:sample_length_adjustierung].reset_index()\n",
    "Sample_for_Bootstrap = Returns_for_sample[['Novartis', 'LafargeHolcim',\n",
    "                                           'Logitech', 'Nestle', 'Swiss_Re']]\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "#Loop 1: Alles 5 Mal ausführen und als Excel & Grafik speichern:\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "for y in range(0,Anzahl_Wiederholungen):\n",
    "    BHS = [] #Tabelle mit allen berechneten VaR der BHS-Methode\n",
    "    CBB = [] #Tabelle mit allen berechneten VaR der CBB-Methode\n",
    "    Reality = [] #Tabelle für die jeweiligen 10 Tage, welche für das Backtesting benötigt werden\n",
    "    \n",
    "    #Dynamisch die Dateinamen für das Excel und der Grafik generieren:\n",
    "    excel_name = \"Simulationen/VaR_Simulation_\"+str(alpha)+\"_Sim_\"+str(Anzahl_Simulationen)+\"_length_\"+str(Sample_length)+\"_V\"+str(y+1)+ \".xlsx\"\n",
    "    Bild_name = \"Simulationen/VaR_Simulation_\"+str(alpha)+\"_Sim_\"+str(Anzahl_Simulationen)+\"_length_\"+str(Sample_length)+\"_V\"+str(y+1)+\".png\"\n",
    "    \n",
    "    #---------------------------------------------------------------------------------------------------------------\n",
    "    #Loop 2: Rolling-Window-Methode: 750 Tage für die Durchführung des Bootstrappings + 10 Tage für Backtesting:\n",
    "    #---------------------------------------------------------------------------------------------------------------\n",
    "    for x in range(0, len(Sample_for_Bootstrap)-Sample_length, 10): \n",
    "        Samp = Sample_for_Bootstrap[x:x+Sample_length] \n",
    "\n",
    "        #Nächsten 10 Tagen für das Backtesting wählen, in diskrete Portfolio-Renditen umrechnen und speichern:\n",
    "        T = Sample_for_Bootstrap.iloc[x+Sample_length:x+Sample_length+10]\n",
    "        Real_Sample = T.sum()\n",
    "        diskrete_real = Math.e**(Real_Sample)-1 \n",
    "        diskrete_real = diskrete_real.mean()  \n",
    "        Reality.append(diskrete_real)\n",
    "        \n",
    "        #---------------------------------------------------------------------------------------------------------------\n",
    "        #Loop 3: \n",
    "            #Bootstrap Historical Simulation & Circular Bootstrap anwenden\n",
    "            #mit n Simulationen & zeitliche Addition der Log-Returns \n",
    "            #umrechnen in diskrete Returns und berechnung Mittelwert für Portfolio-Rendite:\n",
    "        #---------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "        #---------------------------------------------------------------------------------------------------------------\n",
    "        #Bootstrap Historical Simulation (BHS): 10 Tage nach Zufall mit Zurücklegen ziehen und dies 1000 mal wiederholen:\n",
    "        #---------------------------------------------------------------------------------------------------------------\n",
    "        BHS_VaR = []\n",
    "        for x in range(0,Anzahl_Simulationen):\n",
    "            Stichproben = Samp.sample(n=10, replace=True).sum()\n",
    "            df2 = Math.e**(Stichproben)-1 \n",
    "            x = df2.mean() \n",
    "            BHS_VaR.append([x])   \n",
    "\n",
    "        #---------------------------------------------------------------------------------------------------------------\n",
    "        #Circular Block Bootstrap (CBB): 10-Tages-Blöcke mit Circular-Effekt ziehen und dies 1000 mal wiederholen:\n",
    "        #---------------------------------------------------------------------------------------------------------------\n",
    "        CBB_VaR = [] \n",
    "        for x in range(0,Anzahl_Simulationen):    \n",
    "            Random_X_from = np.random.randint(0,Sample_length+1)\n",
    "            Random_X_to = Random_X_from + 10\n",
    "            Stichproben_CBB = Samp[Random_X_from:Random_X_to]\n",
    "            \n",
    "            #-------------------------------------------------------------------------\n",
    "            #Circular-Effekt: Das Ende des Samples mit dem Anfang verbinden -> über den Rand\n",
    "            #-------------------------------------------------------------------------\n",
    "            if Random_X_to > Sample_length: #Überprüfen, ob Block über den Rand geht.\n",
    "                Random_X_to_Circle = (Random_X_to-Sample_length) #Anzahl fehlende Tage berechnen\n",
    "                Rest_Circular = Samp[:Random_X_to_Circle] #Fehlende Tage vom Anfang des Samples holen\n",
    "                Stichproben_CBB = pd.concat([Stichproben_CBB, Rest_Circular]) #Beide Listen zusammenfügen\n",
    "\n",
    "            Stichproben_CBB.sum()\n",
    "            Stichproben_CBB = Stichproben_CBB.sum()\n",
    "            df_CBB = Math.e**(Stichproben_CBB)-1  #Log Renditen in Diskrete Renditen umrechnen\n",
    "            x_CBB = df_CBB.mean()    #Portfolio Rendite rechnen\n",
    "            CBB_VaR.append([x_CBB])    #Tabelle mit 1000 Portfolio Renditen\n",
    "\n",
    "        #---------------------------------------------------------------------------------------------------------------\n",
    "        #Alle 1000 simulierten Portfolio-Renditen aufsteigend sortieren und der 51 schlechteste als VaR definieren:\n",
    "        #---------------------------------------------------------------------------------------------------------------\n",
    "        CBB_VaR.sort()\n",
    "        PF_Returns_Simulation_CBB = pd.DataFrame(CBB_VaR)\n",
    "        VaR_CBB = PF_Returns_Simulation_CBB.iloc[Position_VaR]\n",
    "        CBB.append(VaR_CBB)\n",
    "\n",
    "        BHS_VaR.sort()\n",
    "        PF_Returns_Simulation_BHS = pd.DataFrame(BHS_VaR)\n",
    "        a = PF_Returns_Simulation_BHS.iloc[Position_VaR]\n",
    "        BHS.append(a)\n",
    "    \n",
    "    #---------------------------------------------------------------------------------------------------------------\n",
    "    #Die berechneten VaRs der beiden Methoden in neue Tabelle speichern & die tatsächliche 10-Tages-Rendite ergänzen:\n",
    "    #---------------------------------------------------------------------------------------------------------------\n",
    "    Simulationen = pd.DataFrame(BHS)\n",
    "    Simulationen = Simulationen.rename(columns={0:'BHS_VaR'})\n",
    "    Simulationen['CBB_VaR'] = pd.DataFrame(CBB)\n",
    "    Simulationen = Simulationen.reset_index()\n",
    "    Simulationen.drop('index', axis=1, inplace=True)\n",
    "    Simulationen = pd.concat([Simulationen, pd.DataFrame(Reality)], axis=1)\n",
    "    Simulationen = Simulationen.rename(columns={0:'Reality'})\n",
    "    \n",
    "    #---------------------------------------------------------------------------------------------------------------\n",
    "    #Grafik speichern:\n",
    "    #---------------------------------------------------------------------------------------------------------------\n",
    "    Simulationen.plot(figsize=(30,15));\n",
    "    plt.savefig(Bild_name, dpi=400)\n",
    "    \n",
    "    #---------------------------------------------------------------------------------------------------------------\n",
    "    #Anzahl Exceptions & Exceptions Rate berechnen:\n",
    "    #---------------------------------------------------------------------------------------------------------------  \n",
    "    Simulationen['BHS_Exceptions'] = Simulationen.BHS_VaR > Simulationen.Reality\n",
    "    Simulationen['Anzahl_BHS_Exceptions'] = (Simulationen.BHS_VaR > Simulationen['Reality']).sum()\n",
    "    Simulationen['BHS_Exception_Rate'] = Simulationen.Anzahl_BHS_Exceptions/(len(Simulationen))\n",
    "    \n",
    "    Simulationen['CBB_Exceptions'] = Simulationen.CBB_VaR > Simulationen.Reality\n",
    "    Simulationen['Anzahl_CBB_Exceptions'] = (Simulationen.CBB_VaR > Simulationen['Reality']).sum()\n",
    "    Simulationen['CBB_Exception_Rate'] = Simulationen.Anzahl_CBB_Exceptions/(len(Simulationen))\n",
    "    \n",
    "    Simulationen.to_excel(excel_name)\n",
    "    Simulationen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------------------\n",
    "#Abgelegte Excels für das Backtesting einlesen:\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "Sim = [1000, 2000, 3000]\n",
    "LL = [250, 500, 750, 1000]\n",
    "Anzahl_Wiederholungen = 5\n",
    "path = r'C:\\Users\\lione\\OneDrive\\ZHAW\\Bachelor-Arbeit\\Simulationen'\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "#Parameter eingeben: \n",
    "#-----------------------------------------------------------------------------------------------\n",
    "Hypo_alpha = 0.05  #Konfidenzniveau für Hypothesen-Test eingeben !!!!!!!!!!!! 0.25????\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "#Abgelegte Excels für das Backtesting mittels Schlaufen einlesen:\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "Results = pd.DataFrame()\n",
    "\n",
    "for S in Sim:\n",
    "    for L in LL:\n",
    "        for y in range(0,Anzahl_Wiederholungen):\n",
    "            \n",
    "            #-----------------------------------------------------------------------------------------------\n",
    "            #Alle Excel-Files importieren und als DataFrames speichern:\n",
    "            #-----------------------------------------------------------------------------------------------\n",
    "            excel_name = \"\\VaR_Simulation_Sim_\"+str(S)+\"_length_\"+str(L)+\"_V\"+str(y+1)+\".xlsx\" #VaR 95%\n",
    "            import_name = path + excel_name\n",
    "            name = \"S_\"+str(S)+\"_L_\"+str(L)+\"_V\"+str(y+1)\n",
    "            vars()[name] = pd.read_excel(import_name, sep=';', index_col=0).sort_index()\n",
    "            \n",
    "            #-----------------------------------------------------------------------------------------------\n",
    "            #RUNS-TEST:\n",
    "            #Für jedes File den Runs-Test durchführen und den Z-Score und P-Wert speichern:\n",
    "            #-----------------------------------------------------------------------------------------------\n",
    "            vars()[name]['RT_Z_Score_BHS'] = runstest_1samp(vars()[name].BHS_Exceptions, correction=False)[0]\n",
    "            vars()[name]['RT_P_Value_BHS'] = runstest_1samp(vars()[name].BHS_Exceptions, correction=False)[1]\n",
    "            vars()[name]['RT_reject_H0_BHS'] = vars()[name]['RT_P_Value_BHS'] <= Hypo_alpha\n",
    "            \n",
    "            vars()[name]['RT_Z_Score_CBB'] = runstest_1samp(vars()[name].CBB_Exceptions, correction=False)[0]\n",
    "            vars()[name]['RT_P_Value_CBB'] = runstest_1samp(vars()[name].CBB_Exceptions, correction=False)[1]\n",
    "            vars()[name]['RT_reject_H0_CBB'] = vars()[name]['RT_P_Value_CBB'] <= Hypo_alpha\n",
    "            vars()[name]['Run'] = name\n",
    "            \n",
    "            #-----------------------------------------------------------------------------------------------\n",
    "            #Erste Zeile jedes DataFrames wählen und in neue Tabelle mit allen Resultaten speichern:\n",
    "            #-----------------------------------------------------------------------------------------------\n",
    "            First_col = pd.DataFrame(vars()[name].iloc[0])\n",
    "            First_col = First_col.T\n",
    "            Results = pd.concat([Results, First_col])\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "#Tabelle mit den Resultaten optimieren und als Excel exportieren:\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "Results = Results.set_index('Run')\n",
    "Results = Results.drop(['BHS_VaR','CBB_VaR','Reality','BHS_Exceptions', 'CBB_Exceptions'], axis=1)\n",
    "Results = Results.rename(columns= \n",
    "                             {'Anzahl_BHS_Exceptions' : 'BHS_Exceptions'\n",
    "                             ,'Anzahl_CBB_Exceptions' : 'CBB_Exceptions'})\n",
    "Results['Anzahl_Tests'] = Results.BHS_Exceptions / Results.BHS_Exception_Rate\n",
    "Results.to_excel('Results_95.xlsx')\n",
    "Results_95 = Results \n",
    "Results_95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    " \n",
    "\n",
    "\"\"\" create a database connection tool to a SQLite database \"\"\"\n",
    "\n",
    "def create_connection(db_file):\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        print(sqlite3.version)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    create_connection(r\"C:\\Users\\lione\\OneDrive\\ZHAW\\Master\\Semester 2\\AQM\\Python\\your_first_db.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened database successfully\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(r\"C:\\Users\\lione\\OneDrive\\ZHAW\\Master\\Semester 2\\AQM\\Python\\your_first_db.db\")\n",
    "\n",
    "print(\"Opened database successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created successfully\n"
     ]
    }
   ],
   "source": [
    "# Create Table in using SQL and Python\n",
    "conn = sqlite3.connect(r\"C:\\Users\\lione\\OneDrive\\ZHAW\\Master\\Semester 2\\AQM\\Python\\your_first_db.db\")\n",
    "\n",
    "conn.execute('''CREATE TABLE COMPANY1\n",
    "         (ID INT PRIMARY KEY     NOT NULL,\n",
    "         NAME           TEXT    NOT NULL,\n",
    "         AGE            INT     NOT NULL,\n",
    "         ADDRESS        CHAR(50),\n",
    "         SALARY         REAL);''')\n",
    "\n",
    "print(\"Table created successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert information into the table using SQL and Python\n",
    "conn = sqlite3.connect(r\"C:\\Users\\lione\\OneDrive\\ZHAW\\Master\\Semester 2\\AQM\\Python\\your_first_db.db\")\n",
    "\n",
    "conn.execute(\"INSERT INTO COMPANY1(ID,NAME,AGE,ADDRESS,SALARY) VALUES (1, 'Paul', 32, 'California', 20000.00)\");\n",
    "conn.commit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created successfully\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('TestDB1.db')\n",
    "c = conn.cursor()\n",
    "c.execute('''CREATE TABLE COMPANY1\n",
    "         (ID INT PRIMARY KEY     NOT NULL,\n",
    "         NAME           TEXT    NOT NULL,\n",
    "         AGE            INT     NOT NULL,\n",
    "         ADDRESS        CHAR(50),\n",
    "         SALARY         REAL);''')\n",
    "\n",
    "print(\"Table created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information inserted successfully\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('TestDB1.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "c.execute('''INSERT INTO COMPANY1(ID,NAME,AGE,ADDRESS) VALUES (1, 'Adam', 33, 'California')''')\n",
    "conn.commit()\n",
    "\n",
    "print(\"Information inserted successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Retrieval, Database Upload and Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPIAUCSL</th>\n",
       "      <th>WTISPLC</th>\n",
       "      <th>T5YIFRM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-09-01</th>\n",
       "      <td>256.596</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01</th>\n",
       "      <td>257.305</td>\n",
       "      <td>53.96</td>\n",
       "      <td>1.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01</th>\n",
       "      <td>257.788</td>\n",
       "      <td>57.03</td>\n",
       "      <td>1.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01</th>\n",
       "      <td>258.263</td>\n",
       "      <td>59.88</td>\n",
       "      <td>1.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01</th>\n",
       "      <td>258.682</td>\n",
       "      <td>57.52</td>\n",
       "      <td>1.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            CPIAUCSL  WTISPLC  T5YIFRM\n",
       "DATE                                  \n",
       "2019-09-01   256.596    56.95     1.78\n",
       "2019-10-01   257.305    53.96     1.72\n",
       "2019-11-01   257.788    57.03     1.73\n",
       "2019-12-01   258.263    59.88     1.81\n",
       "2020-01-01   258.682    57.52     1.79"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save data from Web Reader to a database\n",
    "start = datetime.datetime(2010, 1, 1)\n",
    "end = datetime.datetime(2020, 1, 1)\n",
    "variables = pd.DataFrame(web.DataReader(['CPIAUCSL', 'WTISPLC','T5YIFRM'], 'fred', start, end))\n",
    "variables.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created successfully\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('Inflation1.db')\n",
    "c = conn.cursor()\n",
    "c.execute('''CREATE TABLE Inflation_data\n",
    "         (DATE TIMESTAMP,\n",
    "         CPIAUCSL           INT    NOT NULL,\n",
    "         WTISPLC            INT     NOT NULL,\n",
    "         T5YIFRM INT)''')\n",
    "\n",
    "print(\"Table created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPIAUCSL</th>\n",
       "      <th>WTISPLC</th>\n",
       "      <th>T5YIFRM</th>\n",
       "      <th>Date1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>217.488</td>\n",
       "      <td>78.22</td>\n",
       "      <td>2.66</td>\n",
       "      <td>2010-01-01 00-00-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-01</th>\n",
       "      <td>217.281</td>\n",
       "      <td>76.42</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2010-02-01 00-00-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-01</th>\n",
       "      <td>217.353</td>\n",
       "      <td>81.24</td>\n",
       "      <td>2.57</td>\n",
       "      <td>2010-03-01 00-00-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-01</th>\n",
       "      <td>217.403</td>\n",
       "      <td>84.48</td>\n",
       "      <td>2.74</td>\n",
       "      <td>2010-04-01 00-00-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-01</th>\n",
       "      <td>217.290</td>\n",
       "      <td>73.84</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2010-05-01 00-00-00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            CPIAUCSL  WTISPLC  T5YIFRM                Date1\n",
       "DATE                                                       \n",
       "2010-01-01   217.488    78.22     2.66  2010-01-01 00-00-00\n",
       "2010-02-01   217.281    76.42     2.60  2010-02-01 00-00-00\n",
       "2010-03-01   217.353    81.24     2.57  2010-03-01 00-00-00\n",
       "2010-04-01   217.403    84.48     2.74  2010-04-01 00-00-00\n",
       "2010-05-01   217.290    73.84     2.45  2010-05-01 00-00-00"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index1=variables.index.strftime('%Y-%m-%d %H-%M-%S')\n",
    "variables['Date1']=index1\n",
    "variables.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121, 4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[217.488, 78.22, 2.66, '2010-01-01 00-00-00'],\n",
       " [217.28099999999998, 76.42, 2.6, '2010-02-01 00-00-00'],\n",
       " [217.35299999999998, 81.24, 2.57, '2010-03-01 00-00-00'],\n",
       " [217.403, 84.48, 2.74, '2010-04-01 00-00-00'],\n",
       " [217.29, 73.84, 2.45, '2010-05-01 00-00-00'],\n",
       " [217.199, 75.35, 2.22, '2010-06-01 00-00-00'],\n",
       " [217.605, 76.37, 2.12, '2010-07-01 00-00-00'],\n",
       " [217.923, 76.82, 2.02, '2010-08-01 00-00-00'],\n",
       " [218.275, 75.31, 2.2, '2010-09-01 00-00-00'],\n",
       " [219.035, 81.9, 2.52, '2010-10-01 00-00-00'],\n",
       " [219.59, 84.14, 2.62, '2010-11-01 00-00-00'],\n",
       " [220.472, 89.04, 2.78, '2010-12-01 00-00-00'],\n",
       " [221.187, 89.42, 2.73, '2011-01-01 00-00-00'],\n",
       " [221.898, 89.58, 2.67, '2011-02-01 00-00-00'],\n",
       " [223.046, 102.94, 2.7, '2011-03-01 00-00-00'],\n",
       " [224.093, 110.04, 2.89, '2011-04-01 00-00-00'],\n",
       " [224.80599999999998, 101.33, 2.6, '2011-05-01 00-00-00'],\n",
       " [224.80599999999998, 96.29, 2.52, '2011-06-01 00-00-00'],\n",
       " [225.395, 97.19, 2.73, '2011-07-01 00-00-00'],\n",
       " [226.106, 86.33, 2.55, '2011-08-01 00-00-00'],\n",
       " [226.597, 85.61, 2.18, '2011-09-01 00-00-00'],\n",
       " [226.75, 86.41, 2.23, '2011-10-01 00-00-00'],\n",
       " [227.169, 97.21, 2.26, '2011-11-01 00-00-00'],\n",
       " [227.22299999999998, 98.57, 2.35, '2011-12-01 00-00-00'],\n",
       " [227.842, 100.24, 2.4, '2012-01-01 00-00-00'],\n",
       " [228.329, 102.25, 2.5, '2012-02-01 00-00-00'],\n",
       " [228.80700000000002, 106.19, 2.57, '2012-03-01 00-00-00'],\n",
       " [229.187, 103.33, 2.57, '2012-04-01 00-00-00'],\n",
       " [228.713, 94.7, 2.4, '2012-05-01 00-00-00'],\n",
       " [228.524, 82.41, 2.48, '2012-06-01 00-00-00'],\n",
       " [228.59, 87.93, 2.49, '2012-07-01 00-00-00'],\n",
       " [229.918, 94.16, 2.64, '2012-08-01 00-00-00'],\n",
       " [231.015, 94.72, 2.72, '2012-09-01 00-00-00'],\n",
       " [231.638, 89.57, 2.82, '2012-10-01 00-00-00'],\n",
       " [231.24900000000002, 86.66, 2.79, '2012-11-01 00-00-00'],\n",
       " [231.22099999999998, 88.25, 2.86, '2012-12-01 00-00-00'],\n",
       " [231.679, 94.69, 2.84, '2013-01-01 00-00-00'],\n",
       " [232.937, 95.32, 2.86, '2013-02-01 00-00-00'],\n",
       " [232.282, 93.05, 2.85, '2013-03-01 00-00-00'],\n",
       " [231.797, 92.07, 2.73, '2013-04-01 00-00-00'],\n",
       " [231.893, 94.8, 2.6, '2013-05-01 00-00-00'],\n",
       " [232.445, 95.8, 2.31, '2013-06-01 00-00-00'],\n",
       " [232.9, 104.61, 2.39, '2013-07-01 00-00-00'],\n",
       " [233.456, 106.57, 2.53, '2013-08-01 00-00-00'],\n",
       " [233.544, 106.29, 2.53, '2013-09-01 00-00-00'],\n",
       " [233.669, 100.54, 2.6, '2013-10-01 00-00-00'],\n",
       " [234.1, 93.86, 2.59, '2013-11-01 00-00-00'],\n",
       " [234.71900000000002, 97.63, 2.65, '2013-12-01 00-00-00'],\n",
       " [235.28799999999998, 94.62, 2.72, '2014-01-01 00-00-00'],\n",
       " [235.547, 100.82, 2.54, '2014-02-01 00-00-00'],\n",
       " [236.028, 100.8, 2.54, '2014-03-01 00-00-00'],\n",
       " [236.468, 102.07, 2.53, '2014-04-01 00-00-00'],\n",
       " [236.918, 102.18, 2.45, '2014-05-01 00-00-00'],\n",
       " [237.231, 105.79, 2.49, '2014-06-01 00-00-00'],\n",
       " [237.498, 103.59, 2.55, '2014-07-01 00-00-00'],\n",
       " [237.46, 96.54, 2.56, '2014-08-01 00-00-00'],\n",
       " [237.477, 93.21, 2.47, '2014-09-01 00-00-00'],\n",
       " [237.43, 84.4, 2.35, '2014-10-01 00-00-00'],\n",
       " [236.983, 75.79, 2.28, '2014-11-01 00-00-00'],\n",
       " [236.252, 59.29, 2.13, '2014-12-01 00-00-00'],\n",
       " [234.747, 47.22, 2.02, '2015-01-01 00-00-00'],\n",
       " [235.342, 50.58, 2.08, '2015-02-01 00-00-00'],\n",
       " [235.976, 47.82, 2.04, '2015-03-01 00-00-00'],\n",
       " [236.222, 54.45, 2.11, '2015-04-01 00-00-00'],\n",
       " [237.00099999999998, 59.27, 2.1, '2015-05-01 00-00-00'],\n",
       " [237.657, 59.82, 2.09, '2015-06-01 00-00-00'],\n",
       " [238.03400000000002, 50.9, 2.15, '2015-07-01 00-00-00'],\n",
       " [238.033, 42.87, 1.99, '2015-08-01 00-00-00'],\n",
       " [237.498, 45.48, 1.88, '2015-09-01 00-00-00'],\n",
       " [237.733, 46.22, 1.82, '2015-10-01 00-00-00'],\n",
       " [238.017, 42.44, 1.87, '2015-11-01 00-00-00'],\n",
       " [237.761, 37.19, 1.78, '2015-12-01 00-00-00'],\n",
       " [237.65200000000002, 31.68, 1.65, '2016-01-01 00-00-00'],\n",
       " [237.33599999999998, 30.32, 1.54, '2016-02-01 00-00-00'],\n",
       " [238.08, 37.55, 1.69, '2016-03-01 00-00-00'],\n",
       " [238.99200000000002, 40.75, 1.76, '2016-04-01 00-00-00'],\n",
       " [239.55700000000002, 46.71, 1.68, '2016-05-01 00-00-00'],\n",
       " [240.222, 48.76, 1.5, '2016-06-01 00-00-00'],\n",
       " [240.101, 44.65, 1.53, '2016-07-01 00-00-00'],\n",
       " [240.545, 44.72, 1.64, '2016-08-01 00-00-00'],\n",
       " [241.176, 45.18, 1.67, '2016-09-01 00-00-00'],\n",
       " [241.74099999999999, 49.78, 1.79, '2016-10-01 00-00-00'],\n",
       " [242.02599999999998, 45.66, 1.97, '2016-11-01 00-00-00'],\n",
       " [242.637, 51.97, 2.05, '2016-12-01 00-00-00'],\n",
       " [243.618, 52.5, 2.13, '2017-01-01 00-00-00'],\n",
       " [244.00599999999997, 53.47, 2.15, '2017-02-01 00-00-00'],\n",
       " [243.892, 49.33, 2.15, '2017-03-01 00-00-00'],\n",
       " [244.19299999999998, 51.06, 2.08, '2017-04-01 00-00-00'],\n",
       " [244.00400000000002, 48.48, 1.91, '2017-05-01 00-00-00'],\n",
       " [244.16299999999998, 45.18, 1.83, '2017-06-01 00-00-00'],\n",
       " [244.243, 46.63, 1.9, '2017-07-01 00-00-00'],\n",
       " [245.183, 48.04, 1.94, '2017-08-01 00-00-00'],\n",
       " [246.435, 49.82, 1.98, '2017-09-01 00-00-00'],\n",
       " [246.62599999999998, 51.58, 1.99, '2017-10-01 00-00-00'],\n",
       " [247.28400000000002, 56.64, 1.95, '2017-11-01 00-00-00'],\n",
       " [247.805, 57.88, 2.04, '2017-12-01 00-00-00'],\n",
       " [248.743, 63.7, 2.15, '2018-01-01 00-00-00'],\n",
       " [249.43900000000002, 62.23, 2.23, '2018-02-01 00-00-00'],\n",
       " [249.581, 62.73, 2.16, '2018-03-01 00-00-00'],\n",
       " [250.146, 66.25, 2.21, '2018-04-01 00-00-00'],\n",
       " [250.77900000000002, 69.98, 2.18, '2018-05-01 00-00-00'],\n",
       " [251.118, 67.87, 2.17, '2018-06-01 00-00-00'],\n",
       " [251.32299999999998, 70.98, 2.2, '2018-07-01 00-00-00'],\n",
       " [251.74900000000002, 68.06, 2.22, '2018-08-01 00-00-00'],\n",
       " [252.239, 70.23, 2.24, '2018-09-01 00-00-00'],\n",
       " [252.862, 70.75, 2.23, '2018-10-01 00-00-00'],\n",
       " [252.657, 56.96, 2.17, '2018-11-01 00-00-00'],\n",
       " [252.551, 49.52, 2.02, '2018-12-01 00-00-00'],\n",
       " [252.47, 51.38, 1.96, '2019-01-01 00-00-00'],\n",
       " [253.135, 54.95, 2.0, '2019-02-01 00-00-00'],\n",
       " [254.273, 58.15, 2.01, '2019-03-01 00-00-00'],\n",
       " [255.16299999999998, 63.86, 2.03, '2019-04-01 00-00-00'],\n",
       " [255.325, 60.83, 1.94, '2019-05-01 00-00-00'],\n",
       " [255.361, 54.66, 1.85, '2019-06-01 00-00-00'],\n",
       " [255.9, 57.35, 1.93, '2019-07-01 00-00-00'],\n",
       " [256.17900000000003, 54.81, 1.79, '2019-08-01 00-00-00'],\n",
       " [256.596, 56.95, 1.78, '2019-09-01 00-00-00'],\n",
       " [257.305, 53.96, 1.72, '2019-10-01 00-00-00'],\n",
       " [257.788, 57.03, 1.73, '2019-11-01 00-00-00'],\n",
       " [258.263, 59.88, 1.81, '2019-12-01 00-00-00'],\n",
       " [258.682, 57.52, 1.79, '2020-01-01 00-00-00']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert data from dataframe into a vector of lists\n",
    "\n",
    "records_to_insert = variables.values.tolist()\n",
    "records_to_insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's upload the data from the FRED to our database\n",
    "\n",
    "c = conn.cursor()\n",
    "c.executemany(\"INSERT INTO Inflation_data(CPIAUCSL,WTISPLC,T5YIFRM,DATE) VALUES (?,?,?,?)\", records_to_insert)    \n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2010-01-01 00-00-00', 217.488, 78.22, 2.66),\n",
       " ('2010-02-01 00-00-00', 217.28099999999998, 76.42, 2.6),\n",
       " ('2010-03-01 00-00-00', 217.35299999999998, 81.24, 2.57),\n",
       " ('2010-04-01 00-00-00', 217.403, 84.48, 2.74),\n",
       " ('2010-05-01 00-00-00', 217.29, 73.84, 2.45),\n",
       " ('2010-06-01 00-00-00', 217.199, 75.35, 2.22),\n",
       " ('2010-07-01 00-00-00', 217.605, 76.37, 2.12),\n",
       " ('2010-08-01 00-00-00', 217.923, 76.82, 2.02),\n",
       " ('2010-09-01 00-00-00', 218.275, 75.31, 2.2),\n",
       " ('2010-10-01 00-00-00', 219.035, 81.9, 2.52),\n",
       " ('2010-11-01 00-00-00', 219.59, 84.14, 2.62),\n",
       " ('2010-12-01 00-00-00', 220.472, 89.04, 2.78),\n",
       " ('2011-01-01 00-00-00', 221.187, 89.42, 2.73),\n",
       " ('2011-02-01 00-00-00', 221.898, 89.58, 2.67),\n",
       " ('2011-03-01 00-00-00', 223.046, 102.94, 2.7),\n",
       " ('2011-04-01 00-00-00', 224.093, 110.04, 2.89),\n",
       " ('2011-05-01 00-00-00', 224.80599999999998, 101.33, 2.6),\n",
       " ('2011-06-01 00-00-00', 224.80599999999998, 96.29, 2.52),\n",
       " ('2011-07-01 00-00-00', 225.395, 97.19, 2.73),\n",
       " ('2011-08-01 00-00-00', 226.106, 86.33, 2.55),\n",
       " ('2011-09-01 00-00-00', 226.597, 85.61, 2.18),\n",
       " ('2011-10-01 00-00-00', 226.75, 86.41, 2.23),\n",
       " ('2011-11-01 00-00-00', 227.169, 97.21, 2.26),\n",
       " ('2011-12-01 00-00-00', 227.22299999999998, 98.57, 2.35),\n",
       " ('2012-01-01 00-00-00', 227.842, 100.24, 2.4),\n",
       " ('2012-02-01 00-00-00', 228.329, 102.25, 2.5),\n",
       " ('2012-03-01 00-00-00', 228.80700000000002, 106.19, 2.57),\n",
       " ('2012-04-01 00-00-00', 229.187, 103.33, 2.57),\n",
       " ('2012-05-01 00-00-00', 228.713, 94.7, 2.4),\n",
       " ('2012-06-01 00-00-00', 228.524, 82.41, 2.48),\n",
       " ('2012-07-01 00-00-00', 228.59, 87.93, 2.49),\n",
       " ('2012-08-01 00-00-00', 229.918, 94.16, 2.64),\n",
       " ('2012-09-01 00-00-00', 231.015, 94.72, 2.72),\n",
       " ('2012-10-01 00-00-00', 231.638, 89.57, 2.82),\n",
       " ('2012-11-01 00-00-00', 231.24900000000002, 86.66, 2.79),\n",
       " ('2012-12-01 00-00-00', 231.22099999999998, 88.25, 2.86),\n",
       " ('2013-01-01 00-00-00', 231.679, 94.69, 2.84),\n",
       " ('2013-02-01 00-00-00', 232.937, 95.32, 2.86),\n",
       " ('2013-03-01 00-00-00', 232.282, 93.05, 2.85),\n",
       " ('2013-04-01 00-00-00', 231.797, 92.07, 2.73),\n",
       " ('2013-05-01 00-00-00', 231.893, 94.8, 2.6),\n",
       " ('2013-06-01 00-00-00', 232.445, 95.8, 2.31),\n",
       " ('2013-07-01 00-00-00', 232.9, 104.61, 2.39),\n",
       " ('2013-08-01 00-00-00', 233.456, 106.57, 2.53),\n",
       " ('2013-09-01 00-00-00', 233.544, 106.29, 2.53),\n",
       " ('2013-10-01 00-00-00', 233.669, 100.54, 2.6),\n",
       " ('2013-11-01 00-00-00', 234.1, 93.86, 2.59),\n",
       " ('2013-12-01 00-00-00', 234.71900000000002, 97.63, 2.65),\n",
       " ('2014-01-01 00-00-00', 235.28799999999998, 94.62, 2.72),\n",
       " ('2014-02-01 00-00-00', 235.547, 100.82, 2.54),\n",
       " ('2014-03-01 00-00-00', 236.028, 100.8, 2.54),\n",
       " ('2014-04-01 00-00-00', 236.468, 102.07, 2.53),\n",
       " ('2014-05-01 00-00-00', 236.918, 102.18, 2.45),\n",
       " ('2014-06-01 00-00-00', 237.231, 105.79, 2.49),\n",
       " ('2014-07-01 00-00-00', 237.498, 103.59, 2.55),\n",
       " ('2014-08-01 00-00-00', 237.46, 96.54, 2.56),\n",
       " ('2014-09-01 00-00-00', 237.477, 93.21, 2.47),\n",
       " ('2014-10-01 00-00-00', 237.43, 84.4, 2.35),\n",
       " ('2014-11-01 00-00-00', 236.983, 75.79, 2.28),\n",
       " ('2014-12-01 00-00-00', 236.252, 59.29, 2.13),\n",
       " ('2015-01-01 00-00-00', 234.747, 47.22, 2.02),\n",
       " ('2015-02-01 00-00-00', 235.342, 50.58, 2.08),\n",
       " ('2015-03-01 00-00-00', 235.976, 47.82, 2.04),\n",
       " ('2015-04-01 00-00-00', 236.222, 54.45, 2.11),\n",
       " ('2015-05-01 00-00-00', 237.00099999999998, 59.27, 2.1),\n",
       " ('2015-06-01 00-00-00', 237.657, 59.82, 2.09),\n",
       " ('2015-07-01 00-00-00', 238.03400000000002, 50.9, 2.15),\n",
       " ('2015-08-01 00-00-00', 238.033, 42.87, 1.99),\n",
       " ('2015-09-01 00-00-00', 237.498, 45.48, 1.88),\n",
       " ('2015-10-01 00-00-00', 237.733, 46.22, 1.82),\n",
       " ('2015-11-01 00-00-00', 238.017, 42.44, 1.87),\n",
       " ('2015-12-01 00-00-00', 237.761, 37.19, 1.78),\n",
       " ('2016-01-01 00-00-00', 237.65200000000002, 31.68, 1.65),\n",
       " ('2016-02-01 00-00-00', 237.33599999999998, 30.32, 1.54),\n",
       " ('2016-03-01 00-00-00', 238.08, 37.55, 1.69),\n",
       " ('2016-04-01 00-00-00', 238.99200000000002, 40.75, 1.76),\n",
       " ('2016-05-01 00-00-00', 239.55700000000002, 46.71, 1.68),\n",
       " ('2016-06-01 00-00-00', 240.222, 48.76, 1.5),\n",
       " ('2016-07-01 00-00-00', 240.101, 44.65, 1.53),\n",
       " ('2016-08-01 00-00-00', 240.545, 44.72, 1.64),\n",
       " ('2016-09-01 00-00-00', 241.176, 45.18, 1.67),\n",
       " ('2016-10-01 00-00-00', 241.74099999999999, 49.78, 1.79),\n",
       " ('2016-11-01 00-00-00', 242.02599999999998, 45.66, 1.97),\n",
       " ('2016-12-01 00-00-00', 242.637, 51.97, 2.05),\n",
       " ('2017-01-01 00-00-00', 243.618, 52.5, 2.13),\n",
       " ('2017-02-01 00-00-00', 244.00599999999997, 53.47, 2.15),\n",
       " ('2017-03-01 00-00-00', 243.892, 49.33, 2.15),\n",
       " ('2017-04-01 00-00-00', 244.19299999999998, 51.06, 2.08),\n",
       " ('2017-05-01 00-00-00', 244.00400000000002, 48.48, 1.91),\n",
       " ('2017-06-01 00-00-00', 244.16299999999998, 45.18, 1.83),\n",
       " ('2017-07-01 00-00-00', 244.243, 46.63, 1.9),\n",
       " ('2017-08-01 00-00-00', 245.183, 48.04, 1.94),\n",
       " ('2017-09-01 00-00-00', 246.435, 49.82, 1.98),\n",
       " ('2017-10-01 00-00-00', 246.62599999999998, 51.58, 1.99),\n",
       " ('2017-11-01 00-00-00', 247.28400000000002, 56.64, 1.95),\n",
       " ('2017-12-01 00-00-00', 247.805, 57.88, 2.04),\n",
       " ('2018-01-01 00-00-00', 248.743, 63.7, 2.15),\n",
       " ('2018-02-01 00-00-00', 249.43900000000002, 62.23, 2.23),\n",
       " ('2018-03-01 00-00-00', 249.581, 62.73, 2.16),\n",
       " ('2018-04-01 00-00-00', 250.146, 66.25, 2.21),\n",
       " ('2018-05-01 00-00-00', 250.77900000000002, 69.98, 2.18),\n",
       " ('2018-06-01 00-00-00', 251.118, 67.87, 2.17),\n",
       " ('2018-07-01 00-00-00', 251.32299999999998, 70.98, 2.2),\n",
       " ('2018-08-01 00-00-00', 251.74900000000002, 68.06, 2.22),\n",
       " ('2018-09-01 00-00-00', 252.239, 70.23, 2.24),\n",
       " ('2018-10-01 00-00-00', 252.862, 70.75, 2.23),\n",
       " ('2018-11-01 00-00-00', 252.657, 56.96, 2.17),\n",
       " ('2018-12-01 00-00-00', 252.551, 49.52, 2.02),\n",
       " ('2019-01-01 00-00-00', 252.47, 51.38, 1.96),\n",
       " ('2019-02-01 00-00-00', 253.135, 54.95, 2),\n",
       " ('2019-03-01 00-00-00', 254.273, 58.15, 2.01),\n",
       " ('2019-04-01 00-00-00', 255.16299999999998, 63.86, 2.03),\n",
       " ('2019-05-01 00-00-00', 255.325, 60.83, 1.94),\n",
       " ('2019-06-01 00-00-00', 255.361, 54.66, 1.85),\n",
       " ('2019-07-01 00-00-00', 255.9, 57.35, 1.93),\n",
       " ('2019-08-01 00-00-00', 256.17900000000003, 54.81, 1.79),\n",
       " ('2019-09-01 00-00-00', 256.596, 56.95, 1.78),\n",
       " ('2019-10-01 00-00-00', 257.305, 53.96, 1.72),\n",
       " ('2019-11-01 00-00-00', 257.788, 57.03, 1.73),\n",
       " ('2019-12-01 00-00-00', 258.263, 59.88, 1.81),\n",
       " ('2020-01-01 00-00-00', 258.682, 57.52, 1.79)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's now select the data from the database and pull them to python \n",
    "c = conn.cursor()\n",
    "c.execute(\"SELECT * FROM Inflation_data\")\n",
    "new_data=c.fetchall()\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>CPI</th>\n",
       "      <th>WTI</th>\n",
       "      <th>T5YI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-01 00-00-00</td>\n",
       "      <td>217.488</td>\n",
       "      <td>78.22</td>\n",
       "      <td>2.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-02-01 00-00-00</td>\n",
       "      <td>217.281</td>\n",
       "      <td>76.42</td>\n",
       "      <td>2.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-03-01 00-00-00</td>\n",
       "      <td>217.353</td>\n",
       "      <td>81.24</td>\n",
       "      <td>2.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-01 00-00-00</td>\n",
       "      <td>217.403</td>\n",
       "      <td>84.48</td>\n",
       "      <td>2.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-05-01 00-00-00</td>\n",
       "      <td>217.290</td>\n",
       "      <td>73.84</td>\n",
       "      <td>2.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date      CPI    WTI  T5YI\n",
       "0  2010-01-01 00-00-00  217.488  78.22  2.66\n",
       "1  2010-02-01 00-00-00  217.281  76.42  2.60\n",
       "2  2010-03-01 00-00-00  217.353  81.24  2.57\n",
       "3  2010-04-01 00-00-00  217.403  84.48  2.74\n",
       "4  2010-05-01 00-00-00  217.290  73.84  2.45"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert the lists into dataframe\n",
    "new_data=pd.DataFrame(new_data,columns=['Date', 'CPI', 'WTI', 'T5YI'])\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPI</th>\n",
       "      <th>WTI</th>\n",
       "      <th>T5YI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-01 00-00-00</th>\n",
       "      <td>217.488</td>\n",
       "      <td>78.22</td>\n",
       "      <td>2.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-01 00-00-00</th>\n",
       "      <td>217.281</td>\n",
       "      <td>76.42</td>\n",
       "      <td>2.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-01 00-00-00</th>\n",
       "      <td>217.353</td>\n",
       "      <td>81.24</td>\n",
       "      <td>2.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-01 00-00-00</th>\n",
       "      <td>217.403</td>\n",
       "      <td>84.48</td>\n",
       "      <td>2.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-01 00-00-00</th>\n",
       "      <td>217.290</td>\n",
       "      <td>73.84</td>\n",
       "      <td>2.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-01 00-00-00</th>\n",
       "      <td>256.596</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01 00-00-00</th>\n",
       "      <td>257.305</td>\n",
       "      <td>53.96</td>\n",
       "      <td>1.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 00-00-00</th>\n",
       "      <td>257.788</td>\n",
       "      <td>57.03</td>\n",
       "      <td>1.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01 00-00-00</th>\n",
       "      <td>258.263</td>\n",
       "      <td>59.88</td>\n",
       "      <td>1.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00-00-00</th>\n",
       "      <td>258.682</td>\n",
       "      <td>57.52</td>\n",
       "      <td>1.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         CPI    WTI  T5YI\n",
       "Date                                     \n",
       "2010-01-01 00-00-00  217.488  78.22  2.66\n",
       "2010-02-01 00-00-00  217.281  76.42  2.60\n",
       "2010-03-01 00-00-00  217.353  81.24  2.57\n",
       "2010-04-01 00-00-00  217.403  84.48  2.74\n",
       "2010-05-01 00-00-00  217.290  73.84  2.45\n",
       "...                      ...    ...   ...\n",
       "2019-09-01 00-00-00  256.596  56.95  1.78\n",
       "2019-10-01 00-00-00  257.305  53.96  1.72\n",
       "2019-11-01 00-00-00  257.788  57.03  1.73\n",
       "2019-12-01 00-00-00  258.263  59.88  1.81\n",
       "2020-01-01 00-00-00  258.682  57.52  1.79\n",
       "\n",
       "[121 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's set a new index \n",
    "new_data.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
